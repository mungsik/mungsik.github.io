---
title : PEFT ê¸°ë²•ê³¼ LoRA
date : 2024-05-12 22:15:00 +09:00
categories : [PEFT]
tags : [oeft, adapter, lora] #ì†Œë¬¸ìë§Œ ê°€ëŠ¥
description: PEFT ê¸°ë²•ê³¼ LoRAì— ëŒ€í•´ ì•Œì•„ë³´ì
toc: true
toc_sticky: true
toc_label: ëª©ì°¨
math: true
mermaid: true
image: /assets/img/post/PEFT_LoRA/01.png
---

> ìµœê·¼ í•«í•œ PEFT ê¸°ë²•ê³¼ ê·¸ ì¤‘ LoRA ê¸°ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## PEFTì™€ LoRA

### PEFTë€?
---

![Encoder](/assets/img/post/PEFT_LoRA/02.png){:style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }

PEFTë€ Hugging faceì—ì„œ ì†Œê°œí•œ ë°©ë²•ì´ë‹¤. Parameter-Efficient Fine-Tuning (ì´í•˜ PEFT)ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ íŠ¹ì • ìƒí™©ì— ì ìš©í•  ë•Œ, ëŒ€ë¶€ë¶„ì˜ íŒŒë¼ë¯¸í„°ë¥¼ freeze í•˜ê³  ì†Œìˆ˜ì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë§Œ íŒŒì¸ íŠœë‹í•˜ëŠ” ê¸°ë²•ì´ë‹¤. Hugging Faceì—ì„œëŠ” LoRA, Prefix Tuning, Prompt Tuning ê¸°ë²• ë“±ì„ ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë§Œë“¤ì–´ ë†¨ë‹¤.

[Huggingface PEFT ë§í¬](https://huggingface.co/docs/peft/index)

ìœ„ ë§í¬ì— ê°€ë©´ PEFT ê¸°ë²•ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ë©”ì†Œë“œë“¤ì„ ë³¼ ìˆ˜ ìˆë‹¤.

**ì¥ì **

- Reduced Parameter Fine-tuning(ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° íŒŒì¸íŠœë‹)
    
    ì‚¬ì „ í•™ìŠµëœ LLM ëª¨ë¸ì—ì„œ ëŒ€ë‹¤ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê³ ì •í•´ ì†Œìˆ˜ì˜ ì¶”ê°€ì ì¸ íŒŒë¼ë¯¸í„°ë§Œ íŒŒì¸íŠœë‹í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥
    
- Overcoming Catastrophic Forgetting(ì¹˜ëª…ì  ë§ê° ë¬¸ì œ ê·¹ë³µ)
    
    Catastrophic Forgetting ë¬¸ì œëŠ” LLM ëª¨ë¸ ì „ì²´ë¥¼ íŒŒì¸ íŠœë‹í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒì¸ë°, ì´ë¥¼ PEFT ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì™„í™”í•  ìˆ˜ ìˆë‹¤
    
- Application Across Modalities(ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹° ì ìš© ê°€ëŠ¥)
    
    PEFTëŠ” ê¸°ì¡´ ìì—°ì–´ ì²˜ë¦¬ ì˜ì—­ì„ ë„˜ì–´ì„œ ë‹¤ì–‘í•œ ì˜ì—­ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•˜ë‹¤. ìŠ¤í…Œì´ë¸” ë””í“¨ì „, ì»´í“¨í„° ë¹„ì „, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.
    
- Supported PEFT Methods
    
    í—ˆê¹…í˜ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì§€ì›í•œë‹¤. LoRA, Prefix Tuning, í”„ë¡¬í”„íŠ¸ íŠœë‹ ë“± ê°ê°ì˜ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ê²Œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.

### LoRAë€?
---

**ì„œë¡ **

![Encoder](/assets/img/post/PEFT_LoRA/03.png){:style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }

ëª¨ë¸ì´ ì ì  ì»¤ì§ì— ë”°ë¼ fine-tuning í•  ë•Œ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ê°€ ë„ˆë¬´ ë§ì•„ì§€ê³  ì´ì— ë”°ë¥¸ ìì›ì˜ ì œì•½ ë“±ì˜ ë¬¸ì œê°€ ë°œìƒí•˜ê³  ìˆë‹¤. 

ì €ìë“¤ì´ LoRA ì•„ì´ë””ì–´ë¥¼ ì–»ì€ ë…¼ë¬¸(https://arxiv.org/abs/2012.13255) ì´ ìˆëŠ”ë°, í•´ë‹¹ ë…¼ë¬¸ì˜ ì €ìë“¤ì€ PLM(Pretrained Language Model)ì€ low intrinsic dimensionì„ ê°€ì§„ë‹¤ê³  ì£¼ì¥í•œë‹¤. low intrinsic dimension ì´ë€ ë°ì´í„°ì˜ ê³ ìœ  ì°¨ì›ì´ ë‚®ì€ ìƒí™©ì„ ê°€ë¦¬í‚¨ë‹¤. ê°„ë‹¨íˆ ë§í•´, ë°ì´í„°ê°€ ë†’ì€ ì°¨ì›ì—ì„œ í‘œí˜„ë˜ì—ˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ê·¸ë³´ë‹¤ í›¨ì”¬ ë‚®ì€ ì°¨ì›ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ì„¤ëª…ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³ ì°¨ì›ì˜ ë°ì´í„°ê°€ ìˆì„ ë•Œ, ê·¸ ë°ì´í„°ê°€ ì‹¤ì œë¡œëŠ” íŠ¹ì •í•œ ë‚®ì€ ì°¨ì›ì˜ ë¶€ë¶„ ê³µê°„ì— ë†“ì—¬ìˆì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ë³´í†µ over-parameterized modelì´ ê°€ì§€ëŠ” íŠ¹ì§•ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì €ìë“¤ì€ ì´ë¥¼ ì‹¤í—˜ì„ í†µí•´ ì¦ëª…ì„ í–ˆëŠ”ë° RoBERTaì˜ ê²½ìš° ì˜¤ì§ 200 trainable parametersë¡œ 90%ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ëƒˆë‹¤ê³  ì£¼ì¥í•œë‹¤. 

LoRA ë…¼ë¬¸ì˜ ì €ìë“¤ì€ ëª¨ë¸ì˜ low intrinsic dimensionì—ì„œ ë” ë‚˜ì•„ê°€ <span style="color:violet">ê°€ì¤‘ì¹˜ í–‰ë ¬ë„ low intrinsic dimension íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ë‹¤ê³  ì£¼ì¥í•˜ëŠ” ê²ƒ</span>ì´ë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**

- í›ˆë ¨í•  ë•Œ
    - Fine Tuningí•  ë•Œ Pre-trained Modelì˜ WeightsëŠ” ê±´ë“œë¦¬ì§€ ì•Šê² ë‹¤. ì¦‰, `freeze` í•˜ê² ë‹¤.
    - ëŒ€ì‹  ìƒˆë¡œìš´ Weightsë¥¼ ì˜†ì— ë¶™ì—¬ì„œ ì´ Weightsë§Œ í›ˆë ¨ì‹œí‚¤ê² ë‹¤. ì´ Weightsë¥¼ LoRA Weightë¼ê³  í•œë‹¤.
- ì¶”ë¡ í•  ë•Œ
    - ì…ë ¥ê°’ì„ Pre-trained Modelì˜ Weightsì™€ LoRA Weight ëª¨ë‘ì— í†µê³¼ì‹œí‚¨ë‹¤. ìµœì¢… ê²°ê³¼ëŠ” Pre-trained Weightë¥¼ ê±°ì¹œ ê°’ê³¼ LoRA Weightsë¥¼ ê±°ì¹œ ê°’ì„ ë”í•´ì„œ ì‚¬ìš©í•œë‹¤.

**ìˆ˜ì‹ìœ¼ë¡œ ê³µë¶€í•´ë³´ê¸°**

![Encoder](/assets/img/post/PEFT_LoRA/04.png){:style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }


1. ê¸°ì¡´ì˜ LLM ëª¨ë¸ì„ í•˜ë‚˜ì˜ í™•ë¥ í•¨ìˆ˜ PÎ¦(y bar x)ë¼ê³  í•œë‹¤.
2. fine-tuning ê³¼ì •ì—ì„œ LLMì´ íŠœë‹ë˜ëŠ” Î¦ê°€ ìµœì í™” ë˜ëŠ” ì‹ì€ ì‹(1) ì²˜ëŸ¼ í‘œí˜„ëœë‹¤. 
    1. Log-likelihood functionìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ê°€ì¥ ì í•©í•œ íŒŒë¼ë¯¸í„° Î¦ê°€ ë‚˜ì˜¬ í™•ë¥ ì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ë‹¤.
    2. ì§ê´€ì ìœ¼ë¡œ backpropagation í•  ë•Œì˜ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©´,  Î¦ =Â Î¦0 +Â Î”Î¦ ê°€ ëœë‹¤.
3. ì‹(1)ì— ê·¼ê±°í•˜ì—¬ ë§Œì•½ accumulated gradient values(Î”Î¦)ë¥¼ ê¸°ì¡´ë³´ë‹¤ í›¨ì”¬ ì ì€ íŒŒë¼ë¯¸í„°ì¸ Î˜ë¡œ ì¹˜í™˜í•˜ì—¬ Î”Î¦(Î˜)ë¡œ ë‚˜íƒ€ë‚´ë©´ ì‹(2)ë¡œ ë°”ë€Œê²Œ ëœë‹¤.
    1. ì¦‰, ê¸°ì¡´ì˜ log-likelihood ë¬¸ì œì—ì„œ ëª¨ë¸ì´ backpropagation ê³¼ì •ì—ì„œ ì´ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„° ì—°ì‚° ë¬¸ì œë¥¼ ë” ì ì€ íŒŒë¼ë¯¸í„° Î˜ë¡œ ì¹˜í™˜í•˜ì—¬ í’€ê² ë‹¤ëŠ” ì˜ë¯¸.

## Whisperì— PEFT ê¸°ë²• ì ìš©í•˜ê¸°

### PEFT ë„ì… ê³„ê¸°
---

![Encoder](/assets/img/post/PEFT_LoRA/05.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

(ìœ„ ì´ë¯¸ì§€ì—ì„œ whisper_large_0303_ksponspeechë¼ê³  ì“°ì¸ê²Œ íŒŒì¸íŠœë‹í•˜ê³  ìˆëŠ” Whisper ëª¨ë¸ì´ë‹¤.)

- ëª¨ë¸ : whisper-large-v2
- í•™ìŠµ ë°ì´í„° : 1ë§Œê°œ
- í•™ìŠµ ë°ì´í„° ì‹œê°„ : 15h 26m 47s
- ëª¨ë¸ í•™ìŠµ ì‹œê°„ : ì•½ 63ì‹œê°„(ì•½ 2.5ì¼)
- ë°°ì¹˜ ì‚¬ì´ì¦ˆ : 8
- Gradient Accumulation : 4
- ìŠ¤íƒ­(save_points) : 100
- ì‚¬ìš© gpu ë©”ëª¨ë¦¬ : ì•½ 110G

ë„¤.. ì´ê±° ëª»í•©ë‹ˆë‹¤ğŸ¥² ê·¸ë˜ì„œ ì°¾ë‹¤ë³´ë‹ˆ LoRA ê¸°ë²•ì„ Whisperì—ë„ ì ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œê²Œë¨.

### ë¹„êµ
---

![Encoder](/assets/img/post/PEFT_LoRA/06.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

- ì‚¬ìš© gpu ë©”ëª¨ë¦¬ê°€ ì •ë§ ì–´ë§ˆì–´ë§ˆí•˜ê²Œ ì¤„ì€ ê²ƒì„ í™•ì¸
- í•™ìŠµ ì‹œê°„ ë˜í•œ ê°ì†Œ(ë¬¼ë¡  í•™ìŠµ ì‹œê°„ì€ ì˜ë¯¸ x)

ê·¸ë˜ì„œ ì‘ì •í•˜ê³  ë°°ì¹˜ì‚¬ì´ì¦ˆ ëŠ˜ë ¤ì„œ í•™ìŠµì‹œì¼œë´¤ë”ë‹ˆ

- ëª¨ë¸ : whisper-large-v2 + peft ê¸°ë²• ì ìš©
- kspon ë°ì´í„° : 60ë§Œê°œ
- í•™ìŠµ ë°ì´í„° : 54ë§Œê°œ
- í‰ê°€ ë°ì´í„° : 6ë§Œê°œ
- í•™ìŠµ ë°ì´í„° ì‹œê°„ : 840h 32m 45s
- ëª¨ë¸ í•™ìŠµ ì‹œê°„ : ì•½ 400ì‹œê°„(ì•½ 15ì¼) + ì•ŒíŒŒ(ë‹¤ë¥¸ ëª¨ë¸ í•™ìŠµì´ ì§„í–‰ë˜ë©´ í•™ìŠµ ì‹œê°„ì´ ëŠ˜ì–´ë‚¨)
- ì—í­ : 10
- ë°°ì¹˜ ì‚¬ì´ì¦ˆ : 256
- Gradient Accumulation : 2
- ìŠ¤íƒ­ : 100
- ì‚¬ìš© GPU : ì•½ 95G(95000MiB)
- CER : 6í”„ë¡œ(0.06)

ë°°ì¹˜ ì‚¬ì´ì¦ˆë„ ëŠ˜ë¦´ ìˆ˜ ìˆì—ˆê³  CERë„ 0.06ìœ¼ë¡œ ì¢‹ê²Œ ë‚˜ì˜¨ ê²ƒì„ í™•ì¸.

âœ… í•™ìŠµ ì‹œê°„ì´ ì˜ë¯¸ê°€ ì—†ë‹¤?

Whisper ëª¨ë¸ì„ fine-tuning í•  ë•Œ `í•™ìŠµ ì‹œê°„` ì´ ì•„ë‹Œ `step` ì— ì´ˆì ì„ ë‘ì—ˆìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì›Œë‚™ì˜ í° ëª¨ë¸ì´ë¼ í•™ìŠµ ë°ì´í„°ë¥¼ ì•„ë¬´ë¦¬ ì ê²Œí•œë“¤ fine-tuning ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¸ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ `step` ì„ 100ìœ¼ë¡œ ì„¤ì •í•´ë‘ê³  100step ë§ˆë‹¤ ì„±ëŠ¥ ê°œì„ ì´ ì–´ëŠì •ë„ ë˜ëŠ”ì§€ë¥¼ ê´€ì°°í•˜ì˜€ìŠµë‹ˆë‹¤.

## LoRAì— ê´€í•˜ì—¬

### ê·¸ë˜ì„œ ì›ë¦¬ê°€ ë­”ë°?

**ê¸°ë³¸ ê°œë… ì •ë¦¬**

- í–‰ë ¬ì˜ ë­í¬(Rank)
    - í–‰ë ¬ì˜ ì—´ ë˜ëŠ” í–‰ ì¤‘ì— ë‹¤ë¥¸ í–‰ ë˜ëŠ” ì—´ì˜ ì •ìˆ˜ë°°ê°€ ì•„ë‹Œ ì¦‰, `ì„ í˜• ë…ë¦½` ì¸ í–‰ ë˜ëŠ” ì—´ì˜ ìµœëŒ€ ê°œìˆ˜.
    - ì„ í˜• ë…ë¦½ì´ë¼ëŠ” ê²ƒì€ ì–´ë–¤ ë²¡í„°ê°€ ë‹¤ë¥¸ ë²¡í„°ë“¤ì˜ ì„ í˜• ì¡°í•©ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸
    - ì˜ˆë¥¼ ë“¤ì–´, í–‰ë ¬ Aì˜ Rankê°€ `r` ì´ë¼ë©´, ì´ í–‰ë ¬ì€ rê°œì˜ ì„ í˜• ë…ë¦½ì¸ í–‰ ë˜ëŠ” ì—´ ë²¡í„°ë¥¼ ê°€ì§€ê³  ìˆë‹¤ëŠ” ì˜ë¯¸
    - Full Rank í–‰ë ¬
        - í–‰ë ¬ì´ ê°€ëŠ¥í•œ ìµœëŒ€ ë­í¬ë¥¼ ê°–ëŠ” ê²½ìš°ë¥¼ ë§í•¨. ì´ëŠ” í–‰ë ¬ì˜ í–‰ ì „ì²´ ë˜ëŠ” ì—´ ì „ì²´ê°€ ì„ í˜• ë…ë¦½ì¸ ê²½ìš°ë¥¼ ë§í•¨
        - ì˜ˆë¥¼ ë“¤ì–´, m x n í¬ê¸°ì˜ í–‰ë ¬ì—ì„œ í–‰ ì „ì²´ ë­í¬(full row rank)ë¥¼ ê°–ëŠ”ë‹¤ë©´ ì´ëŠ” í–‰ë ¬ì˜ ëª¨ë“  í–‰ ë²¡í„°ë“¤ì´ ì„ í˜• ë…ë¦½ì„ì„ ì˜ë¯¸í•˜ë©°, ì´ ê²½ìš° í–‰ë ¬ì˜ ë­í¬ëŠ” mì´ë‹¤. ì´ëŠ” ì—´ì˜ ê²½ìš°ì—ë„ ë§ˆì°¬ê°€ì§€ì´ë‹¤. ë§Œì•½ í–‰ë ¬ì´ ì—´ ì „ì²´ ë­í¬(full column rank)ë¥¼ ê°–ëŠ”ë‹¤ë©´, ì´ëŠ” í–‰ë ¬ì˜ ëª¨ë“  ì—´ë²¡í„°ë“¤ì´ ì„ í˜• ë…ë¦½ì„ì„ ì˜ë¯¸í•˜ë©°, ì´ ê²½ìš° í–‰ë ¬ì˜ ë­í¬ëŠ” nì´ë‹¤.
        - í–‰ë ¬ì´ ì „ì²´ ë­í¬(full rank)ë¥¼ ê°–ëŠ”ë‹¤ê³  í•  ë•Œ, ì´ëŠ” í–‰ë ¬ì´ ì •ë°©í–‰ë ¬(square matrix, m=n)ì¸ ê²½ìš°ì— í•´ë‹¹í•˜ë©° ëª¨ë“  í–‰ê³¼ ì—´ì´ ì„ í˜• ë…ë¦½ì¸ ê²½ìš°ë¥¼ ì˜ë¯¸í•œë‹¤. ì „ì²´ ë­í¬ë¥¼ ê°–ëŠ” í–‰ë ¬ì€ ì—­í–‰ë ¬ì„ ê°€ì§€ë©°, ë”°ë¼ì„œ ê°€ì—­(invertible) ë˜ëŠ” ë¹„íŠ¹ì´(non-singular)ì´ë¼ê³  ë¶ˆë¦°ë‹¤.
    - Low-Rank í–‰ë ¬
        - í–‰ë ¬ì˜ Rankê°€ í–‰ë ¬ì˜ í–‰ ìˆ˜ë‚˜ ì—´ ìˆ˜ë³´ë‹¤ ì‘ì€ ê²½ìš°. ì¦‰, í–‰ë ¬ì˜ ëª¨ë“  ì •ë³´ë‚˜ êµ¬ì¡°ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ìˆ˜ì˜ í–‰ ë˜ëŠ” ì—´ ë²¡í„°ë“¤ì— ì˜í•´ ì™„ì „íˆ í‘œí˜„ë  ìˆ˜ ìˆëŠ” ê²½ìš°
        - Low-Rank í–‰ë ¬ì€ ì¢…ì¢… ë‘ ê°œ ë˜ëŠ” ê·¸ ì´ìƒì˜ ë” ì‘ì€ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ë¶„í•´ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, m x n í–‰ë ¬ Aê°€ Rank rì¸ ê²½ìš°, AëŠ” m x r í–‰ë ¬ê³¼ r x n í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.
- í–‰ë ¬ ë¶„í•´(Matrix Factorization)
    - ë³µì¡í•œ í–‰ë ¬ì„ ë” ê°„ë‹¨í•˜ê±°ë‚˜ í•´ì„í•˜ê¸° ì‰¬ìš´ ì—¬ëŸ¬ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•œë‹¤. ì´ ë°©ë²•ì€ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŠ¹ì§•ì„ ë°œê²¬í•˜ê³ , ì°¨ì›ì„ ì¶•ì†Œí•˜ë©°, ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” ë° ìœ ìš©í•˜ê²Œ ì‚¬ìš©ëœë‹¤

ğŸ¤”Â ì´ê²Œ LoRAì—ì„œ ì–´ë–»ê²Œ ì“°ì´ëƒ?

í–‰ë ¬ì˜ RankëŠ” ì„ í˜•ì ìœ¼ë¡œ ë…ë¦½ì ì¸ í–‰ ë˜ëŠ” ì—´ì˜ ê°œìˆ˜ì´ë‹¤.

ì¦‰, ë‹¤ë¥¸ í–‰ì´ë‚˜ ì—´ì— ì •ìˆ˜ë¥¼ ê³±í•´ì„œ ë§Œë“¤ ìˆ˜ ì—†ëŠ” ê³ ìœ í•œ í–‰ ë˜ëŠ” ì—´ì˜ ê°œìˆ˜ì´ë‹¤. 

ë‹¤ìŒê³¼ ê°™ì€ 2 x 3 í¬ê¸°ì˜ í–‰ë ¬ x ê°€ ìˆë‹¤ê³  í•  ë•Œ,

$$
\begin{bmatrix}1&2&3\\3&6&9\\ \end{bmatrix}
$$

ë‘ ë²ˆì§¸ í–‰ì´ ì²« ë²ˆì§¸ í–‰ì˜ ì„¸ ë°°ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆëŠ”ë°, ì´ëŠ” í–‰ë ¬ xì— ê³ ìœ  í–‰ì´ í•˜ë‚˜ë§Œ ìˆìœ¼ë¯€ë¡œ ë­í¬ 1 í–‰ë ¬ì´ ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ í–‰ë ¬ xëŠ” ì•„ë˜ì²˜ëŸ¼ ë‘ ê°œì˜ ì‘ì€ í–‰ë ¬ì¸ Aì™€ Bë¡œ ê°ê° í¬ê¸°ê°€ 2x1ê³¼ 1x3ì¸ ë‘ ê°œì˜ ì‘ì€ í–‰ë ¬ë¡œ ë¶„í•´í•  ìˆ˜ ìˆë‹¤.

$$
\begin{bmatrix}1\\3\\ \end{bmatrix} * \begin{bmatrix}1&2&3\\\end{bmatrix} 
=
\begin{bmatrix}1&2&3\\3&6&9\\ \end{bmatrix}
$$

ì´ì œ full-rank í–‰ë ¬ x ëŒ€ì‹  ë‘ ê°œì˜ low-rank í–‰ë ¬ Aì™€ Bë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/07.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ì´ê±¸ ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
h = W_0 x + \Delta W_x = W_0 x + BAx
$$

ì—¬ê¸°ì„œ 

$$
W \approx BA
$$

ë¡œ í‘œí˜„ë  ìˆ˜ ìˆìœ¼ë©° BAëŠ” ì›ë˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ Wì™€ ê°™ì€ ì°¨ì›ì„ ê°€ì§€ì§€ë§Œ ë” ë‚®ì€ ë­í¬ë¥¼ ê°–ëŠ”ë‹¤. `h` ëŠ” í˜„ì¬ ë ˆì´ì–´ì˜ ì¶œë ¥, `W_0` ëŠ” ì‚¬ì „ í•™ìŠµëœ ì›ë˜ ê°€ì¤‘ì¹˜ë¡œ í•™ìŠµ ì¤‘ ê³ ì •ë˜ë©°, `ë¸íƒ€W` ëŠ” ì›ë˜ ê°€ì¤‘ì¹˜ì— ì¶”ê°€ë˜ëŠ” ê°€ì¤‘ì¹˜ë¡œ í•™ìŠµ ì¤‘ ì—…ë°ì´íŠ¸ ëœë‹¤. `BA` ëŠ” low-rank ê°€ì¤‘ì¹˜, xëŠ” ì…ë ¥ì´ë‹¤.

Aì—ëŠ” ë¬´ì‘ìœ„ ê°€ìš°ì‹œì•ˆ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•˜ê³  Bì—ëŠ” 0ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í›ˆë ¨ ì‹œì‘ ì‹œ $\Delta W = BA$ ëŠ” 0ì´ë‹¤. 

Whisper large-v3 ëª¨ë¸ì„ ì˜ˆë¡œ ë“¤ì. ì´ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ëŠ” 1550M ì¦‰, 15.5ì–µê°œì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°–ëŠ” N x M í¬ê¸°ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì´ ìˆëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¬ë©´ Nê³¼ Më³´ë‹¤ ì‘ì€ ìˆ˜ Kë¥¼ ì„ íƒí•˜ì—¬ N x Kì™€ K x M í¬ê¸°ë¥¼ ê°–ëŠ” ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ í–‰ë ¬ UAì™€ UBë¥¼ ìƒì„±í•œë‹¤. UA x UBëŠ” N x Mê³¼ ë˜‘ê°™ì€ í¬ê¸°ì˜ í–‰ë ¬ì„ ìƒì„±í•˜ì§€ë§Œ UAì™€ UB í–‰ë ¬ì— ì €ì¥ëœ íŒŒë¼ë¯¸í„° ê°œìˆ˜ëŠ” ì¤„ê²Œëœë‹¤. ì—¬ê¸°ì„œ KëŠ” íŠœë‹í•´ì•¼í•˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ, Kê°€ ì‘ì„ìˆ˜ë¡ LLM ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤.

ì´ì œ ìœ„ìŠ¤í¼ ëª¨ë¸ì˜ N x M ê°€ì¤‘ì¹˜ í–‰ë ¬ W ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ëŒ€ì‹  UA x UB ê°€ì¤‘ì¹˜ í–‰ë ¬ ë¸íƒ€ Wë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤. Y = m x W + B ë°©ì •ì‹ì—ì„œ ê°€ì¤‘ì¹˜ Wì™€ ë°”ì´ì–´ìŠ¤ BëŠ” íŠœë‹ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤. ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë©´ WëŠ” ì—…ë°ì´íŠ¸ëœ ê°€ì¤‘ì¹˜ Wuê°€ ëœë‹¤. ì—¬ê¸°ì„œ WuëŠ” W+ë¸íƒ€Wë¥¼ ì˜ë¯¸í•œë‹¤. ë¸íƒ€WëŠ” ê¸°ë³¸ ê°€ì¤‘ì¹˜ Wì— ëŒ€í•œ ì—…ë°ì´íŠ¸ëœ ê°€ì¤‘ì¹˜ì´ë‹¤.

$$
Y = m x Wu + B = m(W+\Delta W) + B = m(W+UA * UB) + B
$$

Wë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ëŒ€ì‹  ë¸íƒ€ Wì¦‰, UA * UBë§Œ í•™ìŠµì‹œí‚¨ í›„ , Wì— ë”í•´ì¤€ë‹¤.

ìœ„ ê·¸ë¦¼ì—ì„œ AëŠ” ëœë¤ ê°€ìš°ì‹œì•ˆ ì´ˆê¸°í™”, BëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™” ë˜ì„œ âˆ†WëŠ” í•™ìŠµ ì´ˆê¸°ì—ëŠ” 0ì´ë‹¤. âˆ†WëŠ” Î±/rë¡œ ìŠ¤ì¼€ì¼ë§ í•œë‹¤. (Î±ëŠ” rì—ì„œì˜ constant) Adamìœ¼ë¡œ ìµœì í™”í•  ë•Œ ì´ˆê¸°í™”ë¥¼ ì ì ˆíˆ ìŠ¤ì¼€ì¼ë§ í–ˆë‹¤ë©´, Î±ë¥¼ íŠœë‹í•˜ëŠ” ê²ƒì€ lrì„ íŠœë‹í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ë‹¨ìˆœíˆ Î±ë¥¼ ìš°ë¦¬ê°€ ì‹œë„í•œ ì²« ë²ˆì§¸ rë¡œ ì„¤ì •í•˜ê³  ì¡°ì •í•˜ì§€ ì•ŠëŠ”ë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/10.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

[ì´ë¯¸ì§€ ë§í¬](https://www.youtube.com/watch?v=PXWYUTMt-AU)

ì¦‰, <span style="color:violet">Pre-trained weightì€ frozen í•˜ê³  LoRA weightë§Œ ì—…ë°ì´íŠ¸í•˜ëŠ” ê²ƒì´ë‹¤.</span>

ì•„ë˜ ì½”ì„¸ë¼ì— ìˆëŠ” LoRA ê°•ì˜ ì˜ìƒì„ ìº¡ì³í•´ì™”ë‹¤. ì´ë¯¸ì§€ë¥¼ ë³´ë©´ ì •ë§ ì´í•´ê°€ ì˜ëœë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/11.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ì›ë˜ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì€ ê³ ì •í•˜ê³ , readë§Œ ìˆ˜í–‰í•œë‹¤. ì´ ë•Œ, back-propagationì€ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/11.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

![Encoder](/assets/img/post/PEFT_LoRA/18.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

í•œ ìŒì˜ low-rank decomposition í–‰ë ¬ì„ ë§Œë“¤ê³ , íŒŒì¸ íŠœë‹ì„ í•œë‹¤. ì´ ë•Œ, ë§Œë“¤ì§€ëŠ” low-rank decomposition í–‰ë ¬ì€ ì›ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ì°¨ì›ì´ ê°™ë„ë¡ ì„¤ì •í•œë‹¤. 

![Encoder](/assets/img/post/PEFT_LoRA/12.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì—ì„œëŠ” í•œ ìŒì˜ low-rank decomposition í–‰ë ¬ì„ ê³±í•˜ì—¬ frozen í•´ë†“ì€ ì›ë˜ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ì™€ ê°™ì€ í¬ê¸°ì˜ í–‰ë ¬ì„ ë§Œë“  ë‹¤ìŒ ë‘ í–‰ë ¬ì„ ë”í•˜ì—¬ ì—…ë°ì´íŠ¸í•œë‹¤. ê°•ì˜ì—ì„œ LoRA ê¸°ë²•ì€ ì£¼ë¡œ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ì— ì ìš©ëœë‹¤ê³  í•œë‹¤.

### ê¸°ì¡´ Adapterì™€ LoRAì˜ ì°¨ì´

![Encoder](/assets/img/post/PEFT_LoRA/08.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ê¸°ì¡´ì— ìˆë˜ Adapter

![Encoder](/assets/img/post/PEFT_LoRA/07.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

LoRA

- ì£¼í™©ìƒ‰ ë¶€ë¶„ì´ `adapter` ë¼ëŠ” layerë‹¤. ì´ ë¶€ë¶„ì„ transformer block ì— ì¶”ê°€í•´ì£¼ì–´ ì´ ë¶€ë¶„ë§Œ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ ê¸°ì¡´ fine-tuningì„ ëŒ€ì²´í•˜ëŠ” ê²ƒ.
- ê¸°ì¡´ì— `adapter` ê¸°ë²•ì´ ìˆì—ˆì§€ë§Œ ì´ ê²ƒìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•ŠìŒ. ì‹¤ì œ ë…¼ë¬¸ ì†Œì œëª©ì—ë„ â€œArenâ€™t Existing Solutions Good Enough?â€ ë¼ê³  ë˜ì–´ìˆìŒ.
- ê·¸ë ‡ë‹¤ë©´ ê¸°ì¡´ `adapter` ëŠ” ë¬´ì—‡ì´ ë‹¨ì ì´ì—ˆëŠ”ê°€?
    - ê¸°ì¡´ `adapter` ëŠ” transformer layer ì‚¬ì´ì— adapter layerë¥¼ ì¼ì • Layer ê°œìˆ˜ë§ˆë‹¤ 1ê°œì”© ë°°ì¹˜í•˜ê³  fine tuning ë‹¨ê³„ì—ì„œ adapter layerë§Œ í•™ìŠµí•œë‹¤.
    - ì˜¤ë¥¸ìª½ ê·¸ë¦¼ adapter layerë¥¼ ìì„¸íˆ ë‚˜íƒ€ë‚¸ ê²ƒì¸ë°, ì—¬ê¸°ì„œ feedforward up-projectì™€ feedforward down-projectë§Œ í•™ìŠµí•œë‹¤.
    - ë¬¸ì œì ì€ ì™¼ìª½ ê·¸ë¦¼ì„ ë³´ë©´ adapterì˜ ì—°ì‚°ì´ ì´ë£¨ì–´ì§€ë ¤ë©´ ì•ì„œ multi-headed attentionì˜ ì—°ì‚°ì´ ì´ë£¨ì–´ì ¸ì•¼í•œë‹¤. ì¦‰, sequentially í•˜ê²Œ ì—°ì‚°ì´ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— `inference latency` ê°€ ì¶”ê°€ì ìœ¼ë¡œ ë°œìƒí•œë‹¤.

ğŸ¤” **ê·¸ë ‡ë‹¤ë©´ ê¸°ì¡´ adapterì™€ LoRAì˜ ì°¨ì´ëŠ” ë­˜ê¹Œ?**

![Encoder](/assets/img/post/PEFT_LoRA/08.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

- ì¡´ Adapterì™€ LoRAì˜ ê·¸ë¦¼ì€ ì •ë§ ë¹„ìŠ·í•´ë³´ì¸ë‹¤. ê¸°ì¡´ adapterì—ë„ rì°¨ì›ìœ¼ë¡œ down projection í•˜ëŠ” ë§¤íŠ¸ë¦­ìŠ¤ê°€ ìˆê³  ê·¸ê±¸ ë‹¤ì‹œ up projection í•´ì£¼ëŠ” ë©”íŠ¸ë¦­ìŠ¤ê°€ ìˆë‹¤
- â€˜pre-trained language models have a low â€œinstrisic dimensionâ€ and can still learn efficiently despite a random projection to a smaller subspaceâ€™
    - intrinsic dimension : ëª¨ë¸ì´ ì‹¤ì œë¡œ ì •ë³´ë¥¼ í‘œí˜„í•˜ëŠ”ë° í•„ìš”í•œ ì°¨ì›ì˜ ìˆ˜
    - random projection : ê³ ì°¨ì› ë°ì´í„°ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì €ì°¨ì›ìœ¼ë¡œ ì°¨ì›ì˜ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ê²ƒ.
- ì°¨ì´ëŠ” ë°”ë¡œ <span style="color:violet">LoRA ì—ì„œëŠ” rì°¨ì›ìœ¼ë¡œ ë‚®ì¶”ë©´ì„œë„, ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì••ì¶•í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ. ê·¸ë¦¬ê³  ì´ê±¸ pretrained modeldì—ë§Œ ì ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ê°€ì¤‘ì¹˜ í–‰ë ¬ì—ë„ ì ìš©í•˜ëŠ” ê²ƒ!!</span>

### ê·¸ë˜ì„œ êµ¬í•´ì§„ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ í•˜ëŠ”ë°?
---

- Applying LoRA to Transformer : ë…¼ë¬¸ì—ì„  í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ì˜ ìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì‹ ê²½ë§ì—ì„œ ì–´ë–¤ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ ë¶€ë¶„ì§‘í•©ì— ì ìš©ì´ ê°€ëŠ¥í• ì§€ ê³ ë¯¼í•˜ë‹¤ ì €ìëŠ” parameter-efficiencyë¥¼ ìœ„í•´ downstream taskì— ëŒ€í•´ì„œ attention weightë§Œ adaptingí•˜ê³  MLP(Multi Layer Perceptron)ì—ì„œëŠ” ë™ê²°ì‹œí‚´
- ì¦‰, êµ¬í•´ì§„ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ attention weightì— ëŒ€í•´ ë”í•˜ê±°ë‚˜ ë¹¼ëŠ” ì‹ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥.
- ë”°ë¼ì„œ ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´, ìƒˆë¡œìš´ íƒœìŠ¤í¬ì— ëŒ€í•´ ê¸°ì¡´ ëª¨ë¸ì€ ëƒ…ë‘ê³  ê°ˆì•„ ë¼ìš°ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤.

### ê·¸ë ‡ë‹¤ë©´ ì ì ˆí•œ r ê°’ì´ ë­ì•¼?
---

![Encoder](/assets/img/post/PEFT_LoRA/14.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ëª¨ë“  íŒŒë¼ë¯¸í„°ì— ì ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ W_qì™€ W_vì—ë§Œ ì ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/13.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ì´ë•Œ, `r` ì´ ì¦ê°€í•œë‹¤ê³  ë” ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ ë„ì¶œí•´ë‚´ëŠ” ê²ƒì€ ì•„ë‹˜. ë”°ë¼ì„œ ë‚®ì€ `r` ê°’ìœ¼ë¡œë„ ì¶©ë¶„í•˜ë‹¤ëŠ” ê²ƒì„ ì¦ëª….

â• ì—¬ëŸ¬ ë²ˆ ì‹¤í—˜ì„ í†µí•´ ì ì ˆí•œ r ê°’ì„ ì°¾ì•„ì•¼í•œë‹¤.

### ì˜ˆì‹œ

ì˜ˆë¥¼ ë“¤ì–´, ë©ì‹ì´ë€ ëª¨ë¸ì´ ê°€ì¤‘ì¹˜ê°€ 400000 x 100000 í–‰ë ¬ì„ ê°–ëŠ”ë° ë­í¬ê°€ 10ì´ë¼ë©´ ê°€ì¤‘ì¹˜ëŠ” 400000 x 10 í¬ê¸°ì™€ 10 x 400000 í¬ê¸°ì˜ í–‰ë ¬ì¸ UAì™€ UBë¡œ ë¶„í•´ëœë‹¤. 

íŒŒì¸ íŠœë‹ì„ í•  ê²½ìš°ì—” ì „ì²´ íŒŒë¼ë¯¸í„°ì¸ 40B(400000 x 100000 = 400ì–µê°œ)ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°˜ë©´ LoRAë¥¼ ì‚¬ìš©í•˜ë©´ AUì˜ í¬ê¸° 400ë§Œê°œ(400000 x 10) ì™€ UBì˜ í¬ê¸° 100ë§Œê°œ (10 x 100000)ë§Œ ì—…ë°ì´íŠ¸í•˜ë©´ ëœë‹¤. ì¦‰, ê¸°ì¡´ 400ì–µê°œë³´ë‹¤ ì ì€ 500ë§Œ ê°œì˜ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸í•˜ë©´ ë˜ë¯€ë¡œ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ê°€ ì•½ 98.86% ê°ì†Œí•˜ì—¬ ê³„ì‚°í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì´ ì¤„ê²Œ ëœë‹¤!!

![Encoder](/assets/img/post/PEFT_LoRA/15.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ì‹¤ì œë¡œ Whisper large-v2 ëª¨ë¸ì— ì ìš©í–ˆì„ ë•Œ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ëŠ” ì•½ 1% ë¡œ ë‚˜ì˜¨ë‹¤.

## ì–‘ìí™”(Quantization)

ìœ„ìŠ¤í¼ íŒŒì¸íŠœë‹ì—ëŠ” LoRA ê¸°ë²• + ì–‘ìí™” ê¸°ë²• ì´ ì ìš©ë˜ì—ˆë‹¤. ì´ë¥¼ QLoRAë¼ê³  í•œë‹¤. ì–‘ìí™”ë€ ì‹¤ìˆ˜í˜• ë³€ìˆ˜(floating-point type)ë¥¼ ì •ìˆ˜í˜• ë³€ìˆ˜(integer or fixed point)ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ë‹¤.

![Encoder](/assets/img/post/PEFT_LoRA/16.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

ê·¸ë¦¬ê³  `FP32` íƒ€ì…ì˜ íŒŒë¼ë¯¸í„°ë¥¼ `INT8` í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ”ê²Œ ì¼ë°˜ì ì´ë¼ê³  í•œë‹¤.(ì •ìˆ˜í˜• ë³€ìˆ˜ì˜ bit ìˆ˜ë¥¼ Në°° ì¤„ì´ë©´ ê³±ì…ˆ ë³µì¡ë„ëŠ” N * N ë°°ë¡œ ì¤„ì–´ë“ ë‹¤)

![Encoder](/assets/img/post/PEFT_LoRA/17.png){:style="border:1px solid; border-radius: 7px; padding: 0px;" }

- `FP32` ëŒ€ì‹  `INT8` ì„ ì‚¬ìš©í•œë‹¤ë©´ ë³´í†µ
    - ëª¨ë¸ ì‚¬ì´ì¦ˆ : 1 / 4 ì´ ë˜ê³ 
    - ì¶”ë¡  ì†ë„ : 2 ~ 4ë°° ë¹¨ë¼ì§€ë©°
    - ìš©ëŸ‰ : 2 ~ 4ë°° ê°€ë²¼ì›Œì§„ë‹¤ê³  í•œë‹¤.

FP32 ì—ì„œ INT8 ë¡œ ë³€í™˜ ì‹œ ì •ë³´ ì†ì‹¤ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì—­ìœ¼ë¡œ INT8 ì—ì„œ FP32 ë¡œ ì—­ë³€í™˜í•˜ë©´ ê·¸ëŒ€ë¡œ ë³€í™˜ë˜ì§€ ì•ŠëŠ”ë‹¤. ì´ ë•Œ ë°œìƒí•˜ëŠ” Errorë¥¼ Quantization Error ë¼ê³  í•˜ë©° ì´ Errorë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ì¢‹ì€ Quantization ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.

## ì½”ë“œ 


### config
---

```python
from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model

config = LoraConfig(r=32, lora_alpha=64, target_modules=["q_proj", "v_proj"], lora_dropout=0.05, bias="none")
```

- `r` : update ë˜ëŠ” ê°€ì¤‘ì¹˜ matrixì˜ rank. ì‘ì„ìˆ˜ë¡ trainable paramì´ ì ì–´ì§. ì‘ì„ìˆ˜ë¡ ë§ì´ ì••ì¶•
- `target_modules` : LoRAë¡œ ë°”ê¿€ ëª¨ë“ˆ. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ Transformer ëª¨ë¸ì€ attention blockì—ë§Œ ì ìš©ëœë‹¤. ìœ„ ì½”ë“œì—ì„œë„ qì™€ vì—ë§Œ ì ìš©.
- `lora_alpha` : LoRA scaling factor. scaling ê°’ì´ `lora_alpha / r` ë¡œ ë“¤ì–´ê°„ë‹¤.
    - ìŠ¤ì¼€ì¼ë§ í™í„° : **`lora_alpha`**ëŠ” LoRA ëª¨ë“ˆì— ì˜í•´ ìƒì„±ëœ ë¸íƒ€ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ëŠ” ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¡œ ì‘ë™í•œë‹¤. LoRAì—ì„œ ë¸íƒ€ ê°€ì¤‘ì¹˜ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ í¬ê¸°ì˜ í–‰ë ¬ì„ ì‚¬ìš©í•´ ê³„ì‚°ë˜ë©°, ì´ë¥¼ í†µí•´ ëŒ€í˜• ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ì— ë³€í™”ê°€ ê°€í•´ì§„ë‹¤
    - ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ì˜ ì œì–´ : í•™ìŠµ ì¤‘ì— LoRA ëª¨ë“ˆì´ ì „ì²´ ëª¨ë¸ì— ê°€í•˜ëŠ” ì˜í–¥ë ¥ì„ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. **`lora_alpha`**ì˜ ê°’ì´ í¬ë©´ LoRA ëª¨ë“ˆì— ì˜í•´ ê°€í•´ì§€ëŠ” ê°€ì¤‘ì¹˜ ë³€ê²½ì˜ íš¨ê³¼ê°€ ì»¤ì§€ë©°, ë°˜ëŒ€ë¡œ ì‘ìœ¼ë©´ íš¨ê³¼ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤.
    - í•™ìŠµ ì•ˆì •ì„± : **`lora_alpha`**ë¥¼ ì ì ˆí•œ ê°’ìœ¼ë¡œ ì„¤ì •í•¨ìœ¼ë¡œì¨ ë¸íƒ€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê°€ ë„ˆë¬´ ê³¼ë„í•˜ê²Œ ì ìš©ë˜ê±°ë‚˜, ë°˜ëŒ€ë¡œ ë„ˆë¬´ ë¯¸ë¯¸í•˜ê²Œ ì ìš©ë˜ëŠ” ê²ƒì„ ë§‰ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `bias` : biasë„ í•™ìŠµí•  ê²ƒì¸ì§€ ì„ íƒ. [â€™noneâ€™, â€˜allâ€™, â€˜lora_onlyâ€™] ê°€ ìˆë‹¤. default ê°’ì€ â€˜nonâ€™ ì´ê³  ì´ë¥¼ ì¼œë©´ weight ë¿ë§Œ ì•„ë‹ˆë¼ biasë„ loraë¡œ ì²˜ë¦¬í•œë‹¤.
- `lora_dropout` : LoRA ëª¨ë“ˆì´ íŠ¹ì • ì…ë ¥ í”¼ì²˜ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ë°©ì§€í•œë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì…ë ¥ ë°ì´í„°ì— ê³¼ì í•© ë˜ëŠ” ê²ƒì„ ì¤„ì¸ë‹¤.

### êµ¬í˜„ì²´ 

1. get_peft_model

ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

```python
model = get_peft_model(model, config)
```

2. LoRA Layer

ëª¨ë“  Layerë¥¼ Aì™€ Bë¡œ ê´€ë¦¬í•˜ê³  ìˆë‹¤

```python
class LoraLayer(BaseTunerLayer):
    # All names of layers that may contain (trainable) adapter weights
    adapter_layer_names = ("lora_A", "lora_B", "lora_embedding_A", "lora_embedding_B")
    # All names of other parameters that may contain adapter-related parameters
    other_param_names = ("r", "lora_alpha", "scaling", "lora_dropout")
```

3. Linear

Q. ê¸°ì¡´ weightì™€ LoRA weightì„ ì–´ë–»ê²Œ merge í•˜ëŠ”ê±°ì§€?

A. proj_k, proj_qì™€ ê°™ì€ ëª¨ë“ˆ keyì— í•´ë‹¹í•˜ëŠ” ë ˆì´ì–´ weightì˜ `get_delta_weight` outputê³¼ ê¸°ì¡´ì˜ weightì„ ë‹¨ìˆœíˆ ë”í•´ì£¼ëŠ” í˜•íƒœì´ë‹¤.

```python
def merge(self, safe_merge: bool = False, adapter_names: Optional[list[str]] = None) -> None:
        """
        Merge the active adapter weights into the base weights

        Args:
            safe_merge (`bool`, *optional*):
                If True, the merge operation will be performed in a copy of the original weights and check for NaNs
                before merging the weights. This is useful if you want to check if the merge operation will produce
                NaNs. Defaults to `False`.
            adapter_names (`list[str]`, *optional*):
                The list of adapter names that should be merged. If None, all active adapters will be merged. Defaults
                to `None`.
        """
        adapter_names = check_adapters_to_merge(self, adapter_names)
        if not adapter_names:
            # no adapter to merge
            return

        for active_adapter in adapter_names:
            if active_adapter in self.lora_A.keys():
            # key ex) 'proj_k', 'proj_q' ...
                base_layer = self.get_base_layer()
                if safe_merge:
                    # Note that safe_merge will be slower than the normal merge
                    # because of the copy operation.
                    orig_weights = base_layer.weight.data.clone()
                    delta_weight = self.get_delta_weight(active_adapter)
                    ##############################################################
                    # base modelì˜ weightê³¼ lora ê²°ê³¼ë¥¼ í•©ì¹˜ëŠ” ë¶€
                    if not self.use_dora[active_adapter]:
                        orig_weights = orig_weights + delta_weight
                    ##############################################################
                    else:
                        # handle dora
                        # since delta_weight already includes scaling, set it to 1 here
                        weight_norm = self._get_weight_norm(orig_weights, delta_weight, scaling=1).detach()
                        # We need to cache weight_norm because it has to be based on the original weights. We
                        # cannot calculate it on the fly based on the merged weights when unmerging because its a
                        # different value
                        self._cache_store(f"{active_adapter}-weight_norm", weight_norm)
                        dora_factor = self.lora_magnitude_vector[active_adapter] / weight_norm
                        orig_weights = dora_factor.view(-1, 1) * (orig_weights + delta_weight)

                    if not torch.isfinite(orig_weights).all():
                        raise ValueError(
                            f"NaNs detected in the merged weights. The adapter {active_adapter} seems to be broken"
                        )

                    base_layer.weight.data = orig_weights
                else:
                    delta_weight = self.get_delta_weight(active_adapter)
                    if not self.use_dora[active_adapter]:
                        base_layer.weight.data = base_layer.weight.data + delta_weight
                    else:
                        # handle dora
                        # since delta_weight already includes scaling, set it to 1 here
                        weight_norm = self._get_weight_norm(base_layer.weight, delta_weight, scaling=1).detach()
                        # We need to cache weight_norm because it has to be based on the original weights. We
                        # cannot calculate it on the fly based on the merged weights when unmerging because its a
                        # different value
                        self._cache_store(f"{active_adapter}-weight_norm", weight_norm)
                        dora_factor = self.lora_magnitude_vector[active_adapter] / weight_norm
                        new_weight = dora_factor.view(-1, 1) * (base_layer.weight.data + delta_weight)
                        base_layer.weight.data = new_weight

                self.merged_adapters.append(active_adapter)
```

## Reference

- [https://hi-lu.tistory.com/entry/êµ¬í˜„ì²´ë¥¼-í†µí•´-PEFT-lora-ë¥¼-ì•Œì•„ë³´ì](https://hi-lu.tistory.com/entry/%EA%B5%AC%ED%98%84%EC%B2%B4%EB%A5%BC-%ED%86%B5%ED%95%B4-PEFT-lora-%EB%A5%BC-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90)
- https://webnautes.tistory.com/2269
- [ì–‘ìí™”](https://gaussian37.github.io/dl-concept-quantization/)
- https://x2bee.tistory.com/335
- https://taeyuplab.tistory.com/12
- [ì½”ì„¸ë¼ LoRA ê°•ì˜](https://www.coursera.org/lecture/generative-ai-with-llms/peft-techniques-1-lora-NZOVw)
- https://www.youtube.com/watch?v=PXWYUTMt-AU